{"cells":[{"cell_type":"markdown","metadata":{"id":"hruDYotKZ46S"},"source":["# ANNDL - Challenge 1"]},{"cell_type":"markdown","metadata":{"id":"tXGkLDhdYaZd"},"source":["### Importation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1hyWjNe_Dxg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669578982956,"user_tz":-60,"elapsed":81199,"user":{"displayName":"lucryfede sanbara","userId":"00500696994677584125"}},"outputId":"7d710518-7a6c-419a-92ee-066a09501c32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n","Collecting tensorflow\n","  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[K     |████████████████████████████████| 588.3 MB 6.7 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n","Collecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n","\u001b[K     |████████████████████████████████| 6.0 MB 48.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n","Collecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 56.3 MB/s \n","\u001b[?25hCollecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n","Collecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[K     |████████████████████████████████| 439 kB 69.7 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.14.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.10.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n","Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","Successfully installed flatbuffers-22.11.23 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n","Tensorflow:  2.11.0\n","Cython:  0.29.32\n","Numpy:  1.21.6\n","Matploit:  3.2.2\n","Seaborn:  0.11.2\n","Scipy:  1.7.3\n","Scikit-learn:  1.0.2\n","Panda:  1.3.5\n"]}],"source":["import os\n","import random\n","import matplotlib.pyplot as plt\n","import PIL\n","import PIL.Image\n","\n","#updated tensorflow's version to use the ConvNeXt models\n","!pip install --upgrade tensorflow    \n","\n","import tensorflow as tf\n","import cython as ct\n","import numpy as np\n","import matplotlib as mpl\n","import seaborn as sns\n","import scipy as sp\n","import sklearn as sk\n","import pandas as pd\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","\n","print('Tensorflow: ', tf.__version__)\n","print('Cython: ', ct.__version__)\n","print('Numpy: ', np.__version__)\n","print('Matploit: ', mpl.__version__)\n","print('Seaborn: ', sns.__version__)\n","print('Scipy: ', sp.__version__)\n","print('Scikit-learn: ', sk.__version__)\n","print('Panda: ', pd.__version__)"]},{"cell_type":"markdown","metadata":{"id":"7n_1mYW8_XCH"},"source":["### Mounting Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ry4CC4qa_XZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669579332244,"user_tz":-60,"elapsed":26744,"user":{"displayName":"lucryfede sanbara","userId":"00500696994677584125"}},"outputId":"b9118538-cb4d-4736-9e73-15e82f6b0c8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/.shortcut-targets-by-id/1wYXyoEwRqU1umxccIJJH4SamZKzkPV7x/ANNDL/Challenge1\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/'Submission'"]},{"cell_type":"markdown","metadata":{"id":"qMMM15BwXyDP"},"source":["### Turn off Tensorflow warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwaO-GHq_gft"},"outputs":[],"source":["import warnings\n","import logging\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","tf.get_logger().setLevel('INFO')\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.get_logger().setLevel('ERROR')\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"]},{"cell_type":"markdown","metadata":{"id":"ClB4VKymX33v"},"source":["### Set reproducibility seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uu-NxOHl_iNL"},"outputs":[],"source":["seed = 42\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"cvHkqxJyZ46Z"},"source":["### Set parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WbWnzyBKChgK"},"outputs":[],"source":["image_size = 224 #Resizing image  \n","input_shape = (image_size, image_size, 3)\n","epochs = 200\n","neural_network_name = 'convnext_1'\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{"id":"QEIY391yX9SZ"},"source":["### Setting up image generator\n","The image generator is useful for creating a set of modifications for the images. However data it'not loaded yet.\n","Images are divided into 8 folders, one for each class, so we can exploit the ImageDataGenerator to read them from disk."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2mXlzWC_jyD"},"outputs":[],"source":["from keras.applications.convnext import preprocess_input\n","\n","train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    # apply the net preprocessing to our data\n","    preprocessing_function=preprocess_input,\n","    validation_split = 0.2,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='reflect',\n","    brightness_range = [0.7, 1.5],\n","    rotation_range = 30,\n","    shear_range = 0.3\n",")"]},{"cell_type":"markdown","metadata":{"id":"aT0jztjNTXqI"},"source":["### Data loading with ImageGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbn6UeMj_eMp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669579351742,"user_tz":-60,"elapsed":11062,"user":{"displayName":"lucryfede sanbara","userId":"00500696994677584125"}},"outputId":"bbc9418d-2364-4564-a045-c30957123e78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2836 images belonging to 8 classes.\n","Found 706 images belonging to 8 classes.\n"]}],"source":["# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n","#for train and validation sets\n","\n","train_set = train_gen.flow_from_directory(\n","    directory=('Images/Dataset'),\n","    target_size=(image_size, image_size),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=seed,\n","    subset = 'training'\n",")\n","\n","val_set = train_gen.flow_from_directory(\n","    directory=('Images/Dataset'),\n","    target_size=(image_size,image_size),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=batch_size,\n","    classes=None,\n","    shuffle=True,\n","    subset = 'validation',\n","    seed=seed\n",")\n"]},{"cell_type":"markdown","source":["### Callbacks"],"metadata":{"id":"7DQxcepej8qT"}},{"cell_type":"code","source":["# Utility function to create folders and callbacks for training\n","from datetime import datetime\n","\n","def create_folders_and_callbacks(model_name):\n","\n","  exps_dir = os.path.join('Federica/models_TL_pat')\n","  if not os.path.exists(exps_dir):\n","      os.makedirs(exps_dir)\n","\n","  now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","  if not os.path.exists(exp_dir):\n","      os.makedirs(exp_dir)\n","      \n","  callbacks = []\n","\n","  # Model checkpoint\n","  # ----------------\n","  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","  if not os.path.exists(ckpt_dir):\n","      os.makedirs(ckpt_dir)\n","\n","  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n","                                                     save_weights_only=False, # True to save only weights\n","                                                     save_best_only=True) # True to save only the best epoch \n","  callbacks.append(ckpt_callback)\n","\n","  # Visualize Learning on Tensorboard\n","  # ---------------------------------\n","  tb_dir = os.path.join(exp_dir, 'tb_logs')\n","  if not os.path.exists(tb_dir):\n","      os.makedirs(tb_dir)\n","      \n","  # By default shows losses and metrics for both training and validation\n","  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n","                                               profile_batch=0,\n","                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n","  callbacks.append(tb_callback)\n","\n","  # Early Stopping\n","  # --------------\n","  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n","  callbacks.append(es_callback)\n","\n","  return callbacks"],"metadata":{"id":"xRlQDwZPlyIE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transfer Learning"],"metadata":{"id":"V6CvFSxffyqu"}},{"cell_type":"code","source":["#ConvNeXtLarge model \n","supernet = tfk.applications.ConvNeXtXLarge(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_shape=input_shape   \n",")\n","supernet.summary()\n","#tfk.utils.plot_model(supernet)"],"metadata":{"id":"UtMFGqGmgVQY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the supernet as feature extractor\n","supernet.trainable = False\n","\n","tl_model = tfk.models.Sequential()\n","tl_model.add(tfkl.Resizing(image_size, image_size, interpolation=\"bicubic\"))\n","tl_model.add(supernet)\n","tl_model.add(tfkl.GlobalAveragePooling2D())\n","tl_model.add(tfkl.Dropout(0.3))\n","tl_model.add(tfkl.Dense(3072,activation='relu',kernel_initializer='he_normal'))\n","tl_model.add(tfkl.Dense(8,activation='softmax',kernel_initializer='glorot_normal'))\n","\n","# Compile the model\n","tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n","tl_model.build([None, image_size,image_size,3])\n","tl_model.summary()"],"metadata":{"id":"cVe5fHrVgWq1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669580255936,"user_tz":-60,"elapsed":566,"user":{"displayName":"lucryfede sanbara","userId":"00500696994677584125"}},"outputId":"a6f6ad29-fd96-4376-b77c-995dc3e978d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resizing (Resizing)         (None, 224, 224, 3)       0         \n","                                                                 \n"," convnext_xlarge (Functional  (None, 7, 7, 2048)       348147968 \n"," )                                                               \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 3072)              6294528   \n","                                                                 \n"," dense_1 (Dense)             (None, 8)                 24584     \n","                                                                 \n","=================================================================\n","Total params: 354,467,080\n","Trainable params: 6,319,112\n","Non-trainable params: 348,147,968\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Train the model\n","tl_history = tl_model.fit( \n","    x = train_set,\n","    batch_size = batch_size,\n","    epochs = 100,\n","    validation_data = val_set,\n","    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)]\n",").history  "],"metadata":{"id":"HPGPj0kEgYEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#evaluate the model using the val_set\n","model_metrics = tl_model.evaluate(val_set, return_dict=True)  "],"metadata":{"id":"BUdDimlhdphz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fine tuning"],"metadata":{"id":"IN39okexmhzh"}},{"cell_type":"code","source":["# Set all layers to True\n","tl_model.get_layer('convnext_xlarge').trainable = True\n","\n","#The only built-in layer that has non-trainable weights is the BatchNormalization layer\n","for i, layer in enumerate(tl_model.get_layer('convnext_xlarge').layers):\n","  if(layer.__class__.__name__ == 'LayerNormalization'):\n","    layer.trainable = False\n","\n","for i, layer in enumerate(tl_model.get_layer('convnext_xlarge').layers):\n","   print(i, layer.name, layer.__class__.__name__, layer.trainable)\n","tl_model.summary()"],"metadata":{"id":"Zu9SOcWrENIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n","# Fine-tune the model\n","ft_history = tl_model.fit(\n","    x = train_set,\n","    batch_size = batch_size,\n","    epochs = 100,\n","    validation_data = val_set,\n","    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)],\n",").history"],"metadata":{"id":"h3LQ3AHnEW_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the training\n","plt.figure(figsize=(15,5))\n","plt.plot(ft_history['loss'], alpha=.3, label='Training', color='#ff7f0e', linestyle='--')\n","plt.plot(ft_history['val_loss'], label='Validation Fine Tuning', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(ft_history['accuracy'], label='Training', alpha=.8, color='#ff7f0e', linestyle='--')\n","plt.plot(ft_history['val_accuracy'], label='Validation Fine Tuning', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"],"metadata":{"id":"xh-faBDilN_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save best epoch model\n","tl_model.save('Submission/FT_convnextx_large',include_optimizer=False)\n","final_model = tfk.models.load_model('Submission/FT_convnextx_large')"],"metadata":{"id":"ju26s3zISbKW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Results"],"metadata":{"id":"Iu_t-lfxEZRI"}},{"cell_type":"code","source":["model1_metrics = tl_model.evaluate(val_set, return_dict=True)"],"metadata":{"id":"KHFvYlIqSY-S"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.10.8 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"3ff27d4a4ff8b03ffd37cebdc1f27c63e5c00accdc83baa2860e83f3a6e9b334"}}},"nbformat":4,"nbformat_minor":0}